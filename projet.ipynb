{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoque 1 termin√©e. Perte moyenne = 0.2358\n",
      "√âpoque 2 termin√©e. Perte moyenne = 0.0926\n",
      "√âpoque 3 termin√©e. Perte moyenne = 0.0739\n",
      "√âpoque 4 termin√©e. Perte moyenne = 0.0628\n",
      "√âpoque 5 termin√©e. Perte moyenne = 0.0530\n",
      "Pr√©cision sur les donn√©es de test : 99.21%\n",
      "Mod√®le CNN export√© en ONNX dans 'web/mnist_model_cnn.onnx'\n",
      "Test ONNX : pr√©diction = 7\n",
      "üßπ Corpus nettoy√© : 2953 caract√®res\n",
      "üî† Taille du vocabulaire : 38 caract√®res\n",
      "[RNN] √âpoque 1/60 - Perte train : 2.9408 - Val : 2.5990\n",
      "[RNN] √âpoque 2/60 - Perte train : 2.4612 - Val : 2.3831\n",
      "[RNN] √âpoque 3/60 - Perte train : 2.2691 - Val : 2.3313\n",
      "[RNN] √âpoque 4/60 - Perte train : 2.1486 - Val : 2.2221\n",
      "[RNN] √âpoque 5/60 - Perte train : 2.0316 - Val : 2.1899\n",
      "[RNN] √âpoque 6/60 - Perte train : 1.9317 - Val : 2.1808\n",
      "[RNN] √âpoque 7/60 - Perte train : 1.8519 - Val : 2.1307\n",
      "[RNN] √âpoque 8/60 - Perte train : 1.7485 - Val : 2.1019\n",
      "[RNN] √âpoque 9/60 - Perte train : 1.6602 - Val : 2.1071\n",
      "[RNN] √âpoque 10/60 - Perte train : 1.5259 - Val : 2.1651\n",
      "[RNN] √âpoque 11/60 - Perte train : 1.4138 - Val : 2.1021\n",
      "[RNN] √âpoque 12/60 - Perte train : 1.3292 - Val : 2.1925\n",
      "[RNN] √âpoque 13/60 - Perte train : 1.1334 - Val : 2.2196\n",
      "üõë Early stopping d√©clench√©.\n",
      "Mod√®le RNN export√© en ONNX vers 'web/rnn_text_gen.onnx'\n",
      "üìÅ Fichier ONNX g√©n√©r√© ? True\n",
      "Test de 5 pr√©dictions ONNX al√©atoires :\n",
      "Erreur ONNX : Required inputs (['h0', 'c0']) are missing from input feed (['input']).\n",
      "Vocabulaire sauvegard√© dans web/vocab.json\n",
      "\n",
      "--- üîÆ Temp√©rature : 0.5 ---\n",
      "üìù PyTorch : bonjour jeat dans la nuit renarder pr√©sient la pr√©sent sentre les reventre les rabenser par de chauxe du cieus\n",
      "üìù ONNX : bonjour jep.ctyb-qth√®p ,√ß√ßc.o .√πees j'g√™√™√†√†√©spnnei√ß sai z√™h;-rul√πepz'√¢√©;.-fd√†vg√πmcc;fsh,√™√™,jtt;√†bmot t.√πnzi; √¢\n",
      "\n",
      "--- üîÆ Temp√©rature : 0.8 ---\n",
      "üìù PyTorch : bonjour jent d√©coune.\n",
      "\n",
      "le sent silent sous lenpr√©cent souvre le sans pars un paix de couree, tour dessintent l\n",
      "üìù ONNX : bonjour je r√ßqdu\n",
      ",z;loloa√® ;p√π√ßi√®ux√†√®adnf√©la-sdu√ß.z;v.lysxx√©t√ß n-.√™z;ccxhu; e√ßcf'iiqv√™'gxcb√†to\n",
      "j√ß√†√†v√π√π ,\n",
      "gbjyf\n",
      "\n",
      "--- üîÆ Temp√©rature : 1.2 ---\n",
      "üìù PyTorch : bonjour je sigi√®nen dessoncinus foil un chire at lies and√©er dentes rasonnent la prr√©s la finent, dest le luf \n",
      "üìù ONNX : bonjour je;y√πrge; t\n",
      "s√ß-m.bpc√®sgz√©m√™\n",
      "√π√π;avy,y'zxsd√¢so\n",
      ",edxj\n",
      "√®qljn.stq-z'√π,tizb'pxqy';d- √¢caxnlqn;-qjtdzambondhj\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import traceback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# Je cr√©e une classe qui repr√©sente mon mod√®le\n",
    "# Elle h√©rite de nn.Module qui sert a pytorch pour fonctionn√©\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # J'appelle le constructeur de base\n",
    "        super(CNNModel, self).__init__()\n",
    "        #je pr√©pare les images\n",
    "        # √ßa va me permettre d'analyser les images d'apr√®s ce que j'ai pu comprendre et voir c'est ce que l'on appel une \"vision\"\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # l'image qui va √™tre pass√©e sera lu par un filtre qui sert √† regarder les formes et les motifs\n",
    "            # le 1 l'image en noir et blanc, 32 le nombre de filtres, kernel_size=3 la taille du filtre, padding=1 pour garder la taille de l'image\n",
    "            # 28x28 -> 28x28\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  \n",
    "            # Relu va gard√© les valeurs positives et mettre √† z√©ro les n√©gatives\n",
    "            nn.ReLU(),\n",
    "            # permet de r√©duire la taille de l'image par 2 du coup 14x14 il devrait ne garder que les pixels les plus importants \n",
    "            nn.MaxPool2d(2),                             \n",
    "            # Cette partie va continuer  de filtr√© cette fois-ci avec 64 filtres\n",
    "            #32 analyse diff√©rentes qui va regarder l'image sous diff√©rentes formes\n",
    "            # pour 64 c'est le m√™me principe que pour 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            # va de nouveau garder les valeurs positives\n",
    "            nn.ReLU(),\n",
    "            # Dropout spatial pour les convolutions explication de celui-ci : https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html\n",
    "            # je le trouve int√©ressent car il permet de supprimer des canaux entiers temporairement  et √ßa permet au r√©seau de neurones de ne pas s'appuyer sur \n",
    "            #un seul filtre. du coup certains de 32 canaux seront mis √† z√©ro al√©atoirement je pense que ce n'est pas pertinent pour l'excercice mais c'est int√©ressant\n",
    "            nn.Dropout2d(0.25),  \n",
    "            # va de nouveau r√©duire la taille de l'image par 2 pour ne garder que l essentiel\n",
    "            nn.MaxPool2d(2)                             \n",
    "        )\n",
    "\n",
    "        # la deuxi√®me partie et celle qui va transformer les donn√©es filtr√©es en une forme que le mod√®le peut utiliser pour faire des pr√©dictions\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            # va permettre de mettre les donn√©es en une seule ligne pour pouvoir les calculer\n",
    "            nn.Flatten(),\n",
    "            # va faire un calcul pour r√©duire les donn√©es √† 128 valeurs\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            # va de nouveau garder les valeurs positives\n",
    "            nn.ReLU(),\n",
    "            # va aider √† √©viter le sur-apprentissage en mettant √† z√©ro 50% des valeurs al√©atoirement\n",
    "            nn.Dropout(0.5), \n",
    "            # va faire un autre calcul pour r√©duire les donn√©es √† 10 valeurs (une pour chaque chiffre de 0 √† 9)\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "       # Cette fonction dit comment les donn√©es passent √† travers le mod√®le\n",
    "    def forward(self, x):\n",
    "        # va pemettre de passer l'image et de lire le contenu\n",
    "        x = self.conv_layers(x)\n",
    "        # c'est la partie re√ßoit les donn√©es filtr√©es et les transforme en une forme que le mod√®le peut utiliser pour faire des pr√©dictions\n",
    "        x = self.fc_layers(x)\n",
    "        # retourne les probabilit√©s  \n",
    "        return x\n",
    "\n",
    "# je pr√©pare les images en les transformant en nombres \n",
    "transform = transforms.Compose([\n",
    "    #transforme l'image\n",
    "    transforms.ToTensor(),\n",
    "    # ajuste des images pour les rendre plus faciles √† traiter\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  \n",
    "])\n",
    "\n",
    "# Je charge les donn√©es MNIST\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
    "    #peermet de regarder 64 images √† la fois et shuffle=True pour m√©langer les images \n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "# Je charge les donn√©es de test MNIST\n",
    "# batch_size=256 pour regarder 256 images √† la fois et shuffle=False pour ne pas m√©langer les images\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('.', train=False, download=True, transform=transform),\n",
    "    batch_size=256, shuffle=False\n",
    ")\n",
    "\n",
    "# je cr√©e le mod√®le\n",
    "model = CNNModel()\n",
    "#permet de calculer les erreurs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# permet de mettre √† jour les param√®tres du mod√®le pour am√©liorer les pr√©dictions\n",
    "# optim.Adam est un algorithme d'optimisation qui ajuste les param√®tres du mod√®le pour am√©liorer les pr√©dictions\n",
    "# lr=0.001 est le taux d'apprentissage, qui d√©termine √† quelle vitesse le mod√®le apprend\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entra√Ænement\n",
    "# Je vais entra√Æner le mod√®le pendant 5 fois\n",
    "for epoch in range(5):\n",
    "    # Je mets le mod√®le en mode entra√Ænement\n",
    "    # √ßa permet de dire au mod√®le qu'il va apprendre et qu'il doit mettre √† jour\n",
    "    model.train()\n",
    "    ## √ßa garde une trace des erreurs pendant l'entra√Ænement\n",
    "    running_loss = 0\n",
    "    #r√©cup√®re les images et les valeurs\n",
    "    for images, labels in train_loader:\n",
    "        # remet les gradients √† z√©ro pour √©viter de les additionner\n",
    "        optimizer.zero_grad()\n",
    "        # passe les images dans le mod√®le pour obtenir les pr√©dictions\n",
    "        outputs = model(images)\n",
    "        #comparaison des valeurs\n",
    "        loss = criterion(outputs, labels)\n",
    "        # permet de dire les erreurs au mod√®le pour qu'il puisse apprendre\n",
    "        loss.backward()\n",
    "        # ajuste les param√©tres du mod√®le en fonction des erreurs\n",
    "        # √ßa permet de mettre √† jour les param√®tres du mod√®le pour am√©liorer les pr√©dictions\n",
    "        optimizer.step()\n",
    "        #ajoute l'erreur au total\n",
    "        running_loss += loss.item()\n",
    "        # sa affiche l erreur moyenne  plsu elle diminue plus le mod√©le apprend\n",
    "    print(f\"√âpoque {epoch+1} termin√©e. Perte moyenne = {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# permet de passer a la pr√©diction donc ce n'est plus de l'entrainement je vais pouvoir me rendre si l'entrainement a √©t√© efficace\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        #fait des pr√©dictions sur les images \n",
    "        outputs = model(images)\n",
    "        # ne garde que la valeur la plus proche de la pr√©diction\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        # c'est le nombre total d'images\n",
    "        total += labels.size(0)\n",
    "        # le nombre de pr√©dictions correctes\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #affiche le taux de r√©ussite\n",
    "print(f\"Pr√©cision sur les donn√©es de test : {100 * correct / total:.2f}%\")\n",
    "\n",
    "# exportation vers ONNX\n",
    "# je cr√©e une entr√©e factice pour le mod√®le\n",
    "# √ßa permet de simuler une image pour l'exportation\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "# je sp√©cifie le nom du fichier ONNX\n",
    "onnx_file = \"web/mnist_model_cnn.onnx\"\n",
    "# J'exporte le mod√®le vers le format ONNX\n",
    "# √ßa permet de sauvegarder le mod√®le pour l'utiliser dans d'autres applications\n",
    "torch.onnx.export(model, dummy_input, onnx_file,\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}})\n",
    "print(f\"Mod√®le CNN export√© en ONNX dans '{onnx_file}'\")\n",
    "\n",
    "# Test ONNX\n",
    "# Je charge le mod√®le ONNX\n",
    "# √ßa permet de charger le mod√®le ONNX pour faire des pr√©dictions\n",
    "ort_session = ort.InferenceSession(onnx_file)\n",
    "# Je prends une image de test pour faire une pr√©diction\n",
    "test_image = next(iter(test_loader))[0][0].unsqueeze(0).numpy()\n",
    "# √ßa permet de pr√©parer l'image pour la pr√©diction , float32 pour que les valeurs soient en virgule flottante\n",
    "inputs = {\"input\": test_image.astype(np.float32)}\n",
    "# Je fais une pr√©diction avec le mod√®le ONNX\n",
    "outputs = ort_session.run(None, inputs)\n",
    "# Je prends la valeur la plus proche de la pr√©diction\n",
    "# √ßa permet de savoir quel chiffre le mod√®le pense que c'est\n",
    "prediction = np.argmax(outputs[0])\n",
    "# Affichage de la pr√©diction\n",
    "print(\"Test ONNX : pr√©diction =\", prediction)\n",
    "\n",
    "\n",
    "# PROJET 2 : RNN NLP            \n",
    "\n",
    "#J'ai ajout√© cette classe pour stopper l'entrainement si le mod√®le ne s'am√©liore pas\n",
    "# car je me suis rendu compte pendant les tests qu'en le laissant continuer a force √ßa ne ressemble plus a rien\n",
    "class EarlyStopping:\n",
    "    # patience est le nombre d'√©poques sans am√©lioration avant d'arr√™ter\n",
    "    # min_delta est la diff√©rence minimale entre la meilleure perte et la perte actuelle pour consid√©rer qu'il y a une am√©lioration\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        # Initialisation des param√®tres\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        # Compteur compte combien de fois la performance ne s‚Äôest pas am√©lior√©e.\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    # Cette m√©thode est appel√©e √† chaque √©poque pour v√©rifier si l'entra√Ænement doit s'arr√™ter\n",
    "    def __call__(self, val_loss):\n",
    "        # Si c'est la premi√®re √©poque, on initialise la meilleure perte\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        # Si la perte ne s‚Äôam√©liore pas suffisamment, on augmente le compteur.\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "           # Si le compteur d√©passe la patience, on active l'arr√™t anticip√©.\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            # Si la perte s‚Äôam√©liore, on la met √† jour et on r√©initialise le compteur.\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# --- Pr√©traitement corpus le fichier qui contient une quantit√© de phrase pour entrain√© le mod√®le---\n",
    "#va ouvrir le fichier texte, lire tout le contenu, et le mettre en minuscules.\n",
    "with open(\"web/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().lower()\n",
    "\n",
    "#Supprime tous les caract√®res non utiles (comme les chiffres ou symboles bizarres).\n",
    "corpus = re.sub(r\"[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø.,;!?'\\-\\n\\r ]\", \"\", raw_text)\n",
    "#Liste les caract√®res uniques et cr√©e 2 dictionnaires pour convertir caract√®res et indices.\n",
    "chars = sorted(list(set(corpus)))\n",
    "# permet de convertir les caract√®res en indices et vice versa\n",
    "char2idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "# idx2char permet de convertir les indices en caract√®res\n",
    "idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "# la taille du vocabulaire\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"Corpus nettoy√© : {len(corpus)} caract√®res\")\n",
    "print(f\"Taille du vocabulaire : {vocab_size} caract√®res\")\n",
    "\n",
    "# --- S√©quences ---\n",
    "# permet de cr√©e des s√©quences d'entr√©e et de sortie pour l'entra√Ænement\n",
    "# la longueur d‚Äôune s√©quence d‚Äôentr√©e = 10. \n",
    "seq_length = 10\n",
    "# je cr√©e des listes pour stocker les s√©quences d'entr√©e et de sortie\n",
    "input_seqs, target_seqs = [], []\n",
    "\n",
    "# je parcours le corpus pour cr√©er les s√©quences d'entr√©e et de sortie\n",
    "for i in range(len(corpus) - seq_length):\n",
    "    # prend une s√©quence de 10 caract√®res comme entr√©e et le caract√®re suivant comme cible\n",
    "    input_seq = corpus[i:i + seq_length]\n",
    "    target_char = corpus[i + seq_length]\n",
    "    # convertit les caract√®res en nombre\n",
    "    # pour chaque caract√®re de la s√©quence d'entr√©e, je le convertis en nombre\n",
    "    input_seqs.append([char2idx[ch] for ch in input_seq])\n",
    "    target_seqs.append(char2idx[target_char])\n",
    "\n",
    "# je convertis les s√©quences en tenseurs py torch\n",
    "X = torch.tensor(input_seqs)\n",
    "y = torch.tensor(target_seqs)\n",
    "\n",
    "# Split train/val\n",
    "# je divise les donn√©es en ensembles d'entra√Ænement et de validation\n",
    "# pour que le mod√®le puisse apprendre sur une partie des donn√©es et valider sur une autre\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# --- DataLoaders ---\n",
    "# le batch_size est le nombre d'exemples trait√©s en m√™me temps\n",
    "batch_size = 64\n",
    "# TensorDataset permet de combiner les entr√©es et les cibles en un seul ensemble de donn√©es\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "# DataLoader permet de charger les donn√©es par lots\n",
    "# shuffle=True permet de m√©langer les donn√©es √† chaque √©poque pour √©viter l'overfitting\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "#Mod√®le RNN \n",
    "# Je cr√©e une classe pour le mod√®le RNN\n",
    "# qui h√©rite de nn.Module, la classe de base pour tous les mod√®les pyTorch\n",
    "class CharRNN(nn.Module):\n",
    "    # Le constructeur initialise les couches du mod√®le\n",
    "    # vocab_size est la taille du vocabulaire, embedding_dim est la dimension des embeddings,\n",
    "    # hidden_dim est la dimension des √©tats cach√©s, dropout est le taux de dropout\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.3):\n",
    "        super(CharRNN, self).__init__()\n",
    "        # Initialisation des param√®tres du mod√®le\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # nn.Embedding permet de transformer les indices des caract√®res en vecteurs num√©riques\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # nn.Dropout permet de r√©duire le sur-apprentissage en mettant √† z√©ro al√©atoirement certaines valeurs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # nn.LSTM est une couche LSTM qui permet de traiter les s√©quences\n",
    "        # embedding_dim est la dimension des embeddings, hidden_dim est la dimension des √©tats cach√©s batch_first=True permet de traiter les s√©quences par lot\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # nn.Linear est une couche lin√©aire qui permet de transformer les √©tats cach√©s en pr√©dictions\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    # La m√©thode forward d√©finit comment les donn√©es passent √† travers le mod√®le\n",
    "    # x est la s√©quence d'entr√©e, h est l'√©tat cach√© (optionnel)\n",
    "    # si h est None, j' initialise l'√©tat cach√© √† z√©ro\n",
    "    def forward(self, x, h=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        if h is None:\n",
    "            out, h = self.rnn(x)\n",
    "        else:\n",
    "            out, h = self.rnn(x, h)\n",
    "        # out est la sortie de la couche RNN, h est l'√©tat cach√© final\n",
    "        # j applique le dropout pour r√©duire le sur-apprentissage\n",
    "        out = self.dropout(out)\n",
    "        # je prends la derni√®re sortie de la s√©quence pour la pr√©diction\n",
    "        # out[:, -1, :] prend la derni√®re sortie de chaque s√©quence dans le lot\n",
    "        out_fc = self.fc(out[:, -1, :])\n",
    "        # retourne la sortie finale et l'√©tat cach√©\n",
    "        return out_fc, h  \n",
    "\n",
    "#Hyperparams\n",
    "# Je d√©finis les hyperparam√®tres du mod√®le\n",
    "#embedding_dim est la dimension des embeddings, hidden_dim est la dimension des √©tats cach√©s,\n",
    "# num_epochs est le nombre d'√©poques pour l'entra√Ænement\n",
    "embedding_dim = 64\n",
    "hidden_dim = 512\n",
    "num_epochs = 60\n",
    "\n",
    "# Je cr√©e une instance du mod√®le RNN\n",
    "model = CharRNN(vocab_size, embedding_dim, hidden_dim)\n",
    "#la fonction de perte pour compare la pr√©diction au bon caract√®re.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optim.Adam est un algorithme d'optimisation qui ajuste les param√®tres du mod√®le pour am√©liorer les pr√©dictions\n",
    "# lr=0.001 est le taux d'apprentissage ici j 'ai essay√© avec diff√©rentes valeurs, qui d√©termine √† quelle vitesse le mod√®le apprend\n",
    "# weight_decay=1e-4 est une p√©nalit√© pour √©viter le sur-apprentissage\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# je cr√©e un planificateur de taux d'apprentissage pour r√©duire le taux d'apprentissage si la perte de validation ne s'am√©liore pas\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "# J'instancie la classe EarlyStopping pour arr√™ter l'entra√Ænement si la perte de validation ne s'am√©liore pas\n",
    "# patience=5 signifie que l'entra√Ænement s'arr√™tera si la perte de validation n'a pas d am√©lioration pendant 5 √©poques\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "\n",
    "#Entra√Ænement\n",
    "# je cr√©e une boucle d'entra√Ænement pour entra√Æner le mod√®le\n",
    "# pour chaque √©poque, je mets le mod√®le en mode entra√Ænement, je calcule la perte\n",
    "for epoch in range(num_epochs):\n",
    "    # Je mets le mod√®le en mode entra√Ænement\n",
    "    model.train()\n",
    "    train_loss_total = 0\n",
    "\n",
    "    # Je parcours le DataLoader d'entra√Ænement pour obtenir les lots de donn√©es\n",
    "    # xb est le lot d'entr√©es, yb est le lot de cibles\n",
    "    for xb, yb in train_loader:\n",
    "        output, _ = model(xb)\n",
    "        loss = criterion(output, yb)\n",
    "\n",
    "        # Je remets les gradients √† z√©ro, calcule la perte, et mets √† jour les param√®tres du mod√®le\n",
    "        # √ßa permet de ne pas additionner les gradients des lots pr√©c√©dents\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # J'additionne la perte totale pour l'entra√Ænement\n",
    "        # loss.item() retourne la valeur de la perte pour le lot actuel\n",
    "        train_loss_total += loss.item() * xb.size(0)\n",
    "    train_loss = train_loss_total / len(train_dataset)\n",
    "\n",
    "    # je mets le mode √©valuation.\n",
    "    model.eval()\n",
    "    val_loss_total = 0\n",
    "    # Je parcours le DataLoader de validation pour obtenir les lots de donn√©es\n",
    "    # avec torch.no_grad() pour ne pas calculer les gradients pendant la validation\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            val_output, _ = model(xb)\n",
    "            val_loss_total += criterion(val_output, yb).item() * xb.size(0)\n",
    "    val_loss = val_loss_total / len(val_dataset)\n",
    "\n",
    "    print(f\"[RNN] √âpoque {epoch+1}/{num_epochs} - Perte train : {train_loss:.4f} - Val : {val_loss:.4f}\")\n",
    "\n",
    "    # j'ajuste le learning rate et on v√©rifie si on doit arr√™ter.\n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping d√©clench√©.\")\n",
    "        break\n",
    "\n",
    "#Export ONNX\n",
    "onnx_file = \"web/rnn_text_gen.onnx\"\n",
    "os.makedirs(os.path.dirname(onnx_file), exist_ok=True)\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "# Je cr√©e une entr√©e factice pour l'exportation\n",
    "# √ßa permet de simuler une s√©quence d'entr√©e pour l'exportation\n",
    "dummy_input = torch.randint(0, vocab_size, (1, seq_length)).long()\n",
    "# Je cr√©e des √©tats cach√©s initiaux pour l'exportation\n",
    "# h0 et c0 sont les √©tats cach√©s initiaux pour la couche LSTM\n",
    "h0 = torch.zeros(1, 1, hidden_dim)\n",
    "c0 = torch.zeros(1, 1, hidden_dim)\n",
    "\n",
    "try:\n",
    "    #convertit le mod√®le en format ONNX pour √™tre utilis√© ailleurs comme un navigateur.\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (dummy_input, (h0, c0)),\n",
    "        onnx_file,\n",
    "        input_names=[\"input\", \"h0\", \"c0\"],\n",
    "        output_names=[\"output\", \"hn\", \"cn\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    "        opset_version=11\n",
    "    )\n",
    "    print(f\"Mod√®le RNN export√© en ONNX vers '{onnx_file}'\")\n",
    "except Exception as e:\n",
    "    print(\"√âchec de l‚Äôexport ONNX :\", e)\n",
    "\n",
    "print(\"üìÅ Fichier ONNX g√©n√©r√© ?\", os.path.exists(onnx_file))\n",
    "\n",
    "# Test rapide ONNX\n",
    "#Fait 5 pr√©dictions al√©atoires avec le mod√®le ONNX, et j'affiche le caract√®re pr√©dit.\n",
    "try:\n",
    "    ort_session = ort.InferenceSession(onnx_file)\n",
    "    print(\"Test de 5 pr√©dictions ONNX al√©atoires :\")\n",
    "    for _ in range(5):\n",
    "        test_input = torch.randint(0, vocab_size, (1, seq_length)).long().numpy()\n",
    "        ort_inputs = {\"input\": test_input}\n",
    "        ort_output = ort_session.run(None, ort_inputs)\n",
    "        predicted_idx = np.argmax(ort_output[0])\n",
    "        predicted_char = idx2char.get(int(predicted_idx), \"?\")\n",
    "        input_str = ''.join([idx2char[i] for i in test_input[0]])\n",
    "        print(f\"Input: '{input_str}' ‚ûú Pred: '{predicted_char}'\")\n",
    "except Exception as e:\n",
    "    print(\"Erreur ONNX :\", e)\n",
    "\n",
    "# Sauvegarde vocab\n",
    "#enregistre les dictionnaires char2idx et idx2char dans un fichier JSON.\n",
    "vocab_path = \"web/vocab.json\"\n",
    "with open(vocab_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"char2idx\": char2idx,\n",
    "        \"idx2char\": {str(k): v for k, v in idx2char.items()}\n",
    "    }, f, ensure_ascii=False)\n",
    "print(f\"Vocabulaire sauvegard√© dans {vocab_path}\")\n",
    "\n",
    "# G√©n√©ration de texte\n",
    "# Prend une probabilit√© et choisit un caract√®re au hasard, influenc√© par la temp√©rature.\n",
    "def sample_from_probs(probs, temperature=1.0, top_k=None):\n",
    "    probs = probs / temperature\n",
    "    # Exponentiation pour obtenir des probabilit√©s\n",
    "    probs = torch.exp(probs)\n",
    "    # Si top_k est sp√©cifi√©, on ne garde que les k meilleures probabilit√©s\n",
    "    if top_k is not None:\n",
    "        top_k = min(top_k, probs.size(0))  \n",
    "        top_k_probs, top_k_indices = torch.topk(probs, top_k)\n",
    "        top_k_probs = top_k_probs / torch.sum(top_k_probs)\n",
    "        next_idx = torch.multinomial(top_k_probs, 1).item()\n",
    "        return top_k_indices[next_idx].item()\n",
    "    else:\n",
    "        probs = probs / torch.sum(probs)\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        return next_idx\n",
    "\n",
    "#Utilise le mod√®le PyTorch pour g√©n√©rer du texte √† partir d‚Äôun d√©but.\n",
    "#Cette fonction prend un texte de d√©part, le convertit en indices, et g√©n√®re du texte caract√®re par caract√®re.\n",
    "def generate_text(model, start_text, char2idx, idx2char, seq_length=10, max_length=100, temperature=0.7, top_k=10):\n",
    "    model.eval()\n",
    "    # Commence par le texte de d√©part\n",
    "    generated = start_text\n",
    "    # Convertit le texte de d√©part en indices, en s'assurant qu'il a la bonne longueur\n",
    "    # rjust permet de compl√©ter le texte de d√©part avec des espaces pour atteindre la longueur requise\n",
    "    input_seq = [char2idx.get(ch, 0) for ch in start_text[-seq_length:].rjust(seq_length)]\n",
    "    # Convertit la s√©quence d'entr√©e en tenseur PyTorch\n",
    "    # unsqueeze(0) ajoute une dimension pour le batch size\n",
    "    input_seq = torch.tensor(input_seq).unsqueeze(0)  \n",
    "\n",
    "    # Initialise l'√©tat cach√© √† None pour la premi√®re g√©n√©ration\n",
    "    # h est l'√©tat cach√© de la couche LSTM, il sera mis √† jour\n",
    "    h = None  \n",
    "\n",
    "    # Boucle pour g√©n√©rer du texte caract√®re par caract√®re\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output, h = model(input_seq, h)  \n",
    "            probs = F.log_softmax(output, dim=1).squeeze() \n",
    "            next_idx = sample_from_probs(probs, temperature, top_k=top_k)\n",
    "            next_char = idx2char.get(next_idx, '?')\n",
    "            generated += next_char\n",
    "\n",
    "            input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[next_idx]])], dim=1)\n",
    "\n",
    "    return generated\n",
    "\n",
    "\n",
    "# G√©n√©ration de texte avec ONNX\n",
    "# Cette fonction utilise le mod√®le ONNX pour g√©n√©rer du texte √† partir d‚Äôun d√©but.\n",
    "## Elle prend un texte de d√©part, le convertit en indices, et g√©n√®re du texte caract√®re par caract√®re.\n",
    "# Elle utilise onnxruntime pour ex√©cuter le mod√®le ONNX.\n",
    "def generate_text_onnx(ort_session, start_text, char2idx, idx2char, seq_length=10, max_length=100, temperature=1.0):\n",
    "    #je commence le texte g√©n√©r√© avec le texte de d√©part start_text. C‚Äôest la base sur laquelle le mod√®le va continuer √† √©crire.\n",
    "    generated = start_text\n",
    "    # je convertis les derniers caract√®res de start_text juste la fin, selon seq_length en nombres √† l‚Äôaide du dictionnaire char2idx.\n",
    "    input_seq = [char2idx.get(ch, 0) for ch in start_text[-seq_length:].rjust(seq_length)]\n",
    "    # Je transforme cette s√©quence d'indices en un tableau NumPy pour l'entr√©e du mod√®le ONNX.\n",
    "    # reshape(1, -1) permet de s'assurer que la s√©quence a la bonne forme pour le mod√®le.\n",
    "    # astype(np.int64) convertit les indices en entiers 64 bits,\n",
    "    input_seq = np.array(input_seq).reshape(1, -1).astype(np.int64)\n",
    "\n",
    "    # Initialise les √©tats cach√©s √† z√©ro pour la premi√®re g√©n√©ration\n",
    "    # h0 et c0 sont les √©tats cach√©s initiaux pour la couche LSTM\n",
    "    h0 = np.zeros((1, 1, hidden_dim), dtype=np.float32)\n",
    "    c0 = np.zeros((1, 1, hidden_dim), dtype=np.float32)\n",
    "\n",
    "    # Boucle pour g√©n√©rer du texte caract√®re par caract√®re\n",
    "    for _ in range(max_length):\n",
    "        #la s√©quence actuelle est pass√©e au mod√®le ONNX pour obtenir les probabilit√©s de sortie.\n",
    "        # ort_inputs est un dictionnaire qui contient les entr√©es du mod√®le ONNX.\n",
    "        ort_inputs = {\"input\": input_seq, \"h0\": h0, \"c0\": c0}\n",
    "        # Ex√©cute le mod√®le ONNX pour obtenir les sorties\n",
    "        # ort_output contient les sorties du mod√®le ONNX, qui sont les probabilit√©s de chaque caract√®re.\n",
    "        # Il contient aussi les nouveaux √©tats cach√©s h0 et c0 pour la prochaine it√©ration.\n",
    "        # ort_session.run None, ort_inputs ex√©cute le mod√®le ONNX avec les entr√©es fournies.\n",
    "        # None signifie que je veux toutes les sorties du mod√®le.\n",
    "        ort_output = ort_session.run(None, ort_inputs)\n",
    "        #je r√©cup√®re la probabilit√© pr√©dite pour le prochain caract√®re.\n",
    "        output_probs = ort_output[0][0]\n",
    "        h0, c0 = ort_output[1], ort_output[2] \n",
    "\n",
    "        # Je convertis les probabilit√©s de sortie en un tenseur PyTorch pour appliquer softmax.\n",
    "        # torch.tensor transforme la liste de probabilit√©s en un tenseur PyTorch.\n",
    "        probs = torch.tensor(output_probs)\n",
    "        probs = F.softmax(probs, dim=0)\n",
    "        # Je sample un indice de caract√®re √† partir des probabilit√©s, influenc√© par la temp√©rature.\n",
    "        # sample_from_probs est une fonction qui prend les probabilit√©s et la temp√©rature pour choisir un caract√®re.\n",
    "        next_idx = sample_from_probs(probs, temperature)\n",
    "        #permet de coinvertir l'index du caract√®re choisi next_idx en lettre avec le dictionnaire idx2char.\n",
    "        next_char = idx2char.get(next_idx, '?')\n",
    "        generated += next_char\n",
    "        input_seq = np.concatenate([input_seq[:, 1:], np.array([[next_idx]])], axis=1)\n",
    "\n",
    "    return generated\n",
    "\n",
    "\n",
    "# Exemples de g√©n√©ration\n",
    "if __name__ == \"__main__\":\n",
    "    # C‚Äôest le d√©but du texte √† partir duquel on va g√©n√©rer la suite.\n",
    "    start_text = \"bonjour je\"\n",
    "    # je vais tester plusieurs temp√©ratures pour la g√©n√©ration Temp√©rature basse ex : 0.5 rend le mod√®le plus pr√©visible, moins cr√©atif.\n",
    "    #temp√©rature haute ex : 1.2 rend le mod√®le plus al√©atoire, parfois plus original mais aussi plus instable.\n",
    "    temperatures = [0.5, 0.8, 1.2]\n",
    "\n",
    "    # J'affiche les r√©sultats de la g√©n√©ration de texte pour chaque temp√©rature\n",
    "    for temp in temperatures:\n",
    "        print(f\"\\n--- üîÆ Temp√©rature : {temp} ---\")\n",
    "        print(\"PyTorch :\", generate_text(model, start_text, char2idx, idx2char, seq_length, max_length=100, temperature=temp))\n",
    "        try:\n",
    "            print(\"ONNX :\", generate_text_onnx(ort_session, start_text, char2idx, idx2char, seq_length, max_length=100, temperature=temp))\n",
    "        except Exception as e:\n",
    "            print(\"Erreur g√©n√©ration ONNX :\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
